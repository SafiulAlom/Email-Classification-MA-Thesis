{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Skripte laden\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "os.chdir('/home/safiul/email-classification')\n",
    "import data\n",
    "from Email_Classification.Functions.packages import *\n",
    "import Email_Classification.Functions.Functions as fn\n",
    "import Email_Classification.Functions.Helper as hp\n",
    "import Email_Classification.Functions.parameters as par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameterwerte\n",
    "param_process = par.params['param_process']\n",
    "param_nlp = par.params['param_nlp']\n",
    "param_embed = par.params['param_embed']\n",
    "param_conv = par.params['param_conv']\n",
    "param_lstm = par.params['param_lstm']\n",
    "param_optimizer = par.params['param_optimizer']\n",
    "param_fit = par.params['param_fit']\n",
    "prior_params = par.params['prior_params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameterwerte der besten C-LSTM-Modelle\n",
    "#with open('Email_Classification/Models/Sequential Models/rnn/lstm/Models/filters/2020-10-21_1035_filter_200_unit_200_acc_0.7045/param.pkl', 'rb') as f:\n",
    "#    params = pickle.load(f)\n",
    "# param_process = params['param_process']\n",
    "# param_nlp = params['param_nlp']\n",
    "# param_embed = params['param_embed']\n",
    "# param_conv = params['param_conv']\n",
    "# param_lstm = params['param_lstm']\n",
    "# param_optimizer = params['param_optimizer']\n",
    "# param_fit = params['param_fit']\n",
    "# prior_params = params['prior_params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil \n",
    "shutil.make_archive('Email_Classification/final_scripts','zip','Email_Classification/final_scripts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#Dateien laden\n",
    "headers = pd.read_parquet(data.HEADERS_FILE)\n",
    "bodies = pd.read_parquet(data.BODIES_FILE)\n",
    "targets = features.zedsets.prepare_target_most_common(\n",
    "    pd.read_parquet(data.TARGETS_FILE),\n",
    "    target_column='target_category',\n",
    "    num_most_common_class=100\n",
    ")\n",
    "#Der E-Mail-Datensatz mit den notwendigen Spalten erstellen\n",
    "emails = fn.createDataFrameEmail(headers = headers, \n",
    "                                 bodies = bodies, \n",
    "                                 targets = targets, \n",
    "                                 sample_size = param_process['sample_size'], \n",
    "                                 seed = 125)\n",
    "#del headers, bodies, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#Der Datensatz auf Test- und Trainingsmenge aufteilen\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "model_selection.train_test_split(emails.emails, \n",
    "                                 emails.target_category, \n",
    "                                 test_size =  param_process['test_size'], \n",
    "                                 shuffle = True,\n",
    "                                 random_state = 123)\n",
    "#Konvertieren von kategorialen Labels in Zahlen\n",
    "LE = preprocessing.LabelEncoder()\n",
    "LE.fit(emails.target_category)\n",
    "y_train = LE.transform(y_train)\n",
    "y_test = LE.transform(y_test)\n",
    "encoder = LabelBinarizer()\n",
    "encoder_fit = encoder.fit(y_train)\n",
    "y_train = encoder_fit.transform(y_train)\n",
    "y_test = encoder_fit.transform(y_test)\n",
    "del emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#Datenvorverarbeiten\n",
    "TP = fn.Text_process(nchar = param_process['nchar'], \n",
    "                     rmDigits = param_process['rmDigits'], \n",
    "                     trans_lower= param_process['trans_lower'])\n",
    "TP.fit(X_train)\n",
    "X_train_TP = fn.multiprocess_array(TP, X_train)\n",
    "X_test_TP = fn.multiprocess_array(TP, X_test)\n",
    "X_train_TP = pd.concat(X_train_TP)\n",
    "X_test_TP = pd.concat(X_test_TP)\n",
    "\n",
    "X_train_TP_ = X_train_TP[X_train_TP.apply(lambda x: len(x.split())) != 0]\n",
    "X_test_TP_ = X_test_TP[X_test_TP.apply(lambda x: len(x.split())) != 0]\n",
    "y_train = y_train[X_train_TP.apply(lambda x: len(x.split())) != 0]\n",
    "y_test = y_test[X_test_TP.apply(lambda x: len(x.split())) != 0]\n",
    "del X_train, X_test, X_train_TP, X_test_TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#tokenize + padding \n",
    "Embeddings = fn.Embedding_custom(max_feature = param_embed['input_dim'],\n",
    "                           X_train= X_train_TP_,\n",
    "                           X_test= X_test_TP_,\n",
    "                           quantile = param_embed['quantile'])\n",
    "MAXLEN, tokenizer, X_train_vec, X_test_vec =  Embeddings.padding()\n",
    "#Embedding-Matrix erstellen\n",
    "fb_model = load_facebook_model(\"fasttext/cc.de.300.bin\")\n",
    "embedding_matrix = Embeddings.embedding_matrix(fb_model)\n",
    "#with open('Email_Classification/Models/Sequential Models/rnn/lstm/Models/\\\n",
    "#2020-10-05_1932_acc_0.6889/feature/embedding_matrix.npy', 'rb') as f:\n",
    "#    embedding_matrix = np.load(f)\n",
    "del fb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input des besten C-LSTM\n",
    "# with open('Email_Classification/Models/Sequential Models/rnn/lstm/Models/\\\n",
    "#filters/2020-10-21_1035_filter_200_unit_200_acc_0.7045/feature/X_train_vec.npy', 'rb') as f:\n",
    "#     X_train_vec = np.load(f)\n",
    "# with open('Email_Classification/Models/Sequential Models/rnn/lstm/Models/\\\n",
    "#filters/2020-10-21_1035_filter_200_unit_200_acc_0.7045/feature/X_test_vec.npy', 'rb') as f:\n",
    "#     X_test_vec = np.load(f)\n",
    "# with open('Email_Classification/Models/Sequential Models/rnn/lstm/Models/\\\n",
    "#filters/2020-10-21_1035_filter_200_unit_200_acc_0.7045/feature/y_train.npy', 'rb') as f:\n",
    "#     y_train = np.load(f)\n",
    "# with open('Email_Classification/Models/Sequential Models/rnn/lstm/Models/filters/\\\n",
    "#2020-10-21_1035_filter_200_unit_200_acc_0.7045/feature/y_test.npy', 'rb') as f:\n",
    "#     y_test = np.load(f)\n",
    "# with open('Email_Classification/Models/Sequential Models/rnn/lstm/Models/\\\n",
    "#filters/2020-10-21_1035_filter_200_unit_200_acc_0.7045/feature/embedding_matrix.npy', 'rb') as f:\n",
    "#     embedding_matrix = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 323 ms, sys: 257 ms, total: 580 ms\n",
      "Wall time: 278 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#RNN-Modelle initialisieren\n",
    "rnn_model = fn.RNN_custom(param_embed = param_embed, \n",
    "                           param_conv = param_conv, \n",
    "                           param_lstm = param_lstm, \n",
    "                           prior_params = prior_params,\n",
    "                           param_optimizer = param_optimizer, \n",
    "                           param_fit = param_fit,\n",
    "                           method = 'lstm', \n",
    "                           run_vi = True,\n",
    "                           conv_layer = True, \n",
    "                           embedding_matrix = embedding_matrix, \n",
    "                           training = False, \n",
    "                           MAXLEN = 396,\n",
    "                           run_dropout2 = False, \n",
    "                           training2 = False,\n",
    "                           train_size = len(X_train_vec))\n",
    "#Zusammenfassung des Modells\n",
    "rnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Callbacks erstellen\n",
    "now = datetime.datetime.now().strftime(\"%Y-%m-%d_%H%M\")\n",
    "wkd = param_fit['wkd']\n",
    "PATH_CHECKPOINTS = wkd + now\n",
    "if not os.path.isdir(PATH_CHECKPOINTS):\n",
    "    os.mkdir(PATH_CHECKPOINTS)\n",
    "    \n",
    "# Create callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor= param_fit['monitor'], \n",
    "                     patience=  param_fit['patience'], \n",
    "                     min_delta= param_fit['min_delta'], \n",
    "                     mode= param_fit['mode']\n",
    "),\n",
    "    ModelCheckpoint(\n",
    "        #see https://machinelearningmastery.com/check-point-deep-learning-models-keras/\n",
    "        PATH_CHECKPOINTS +  \"/weights.best.hdf5\",\n",
    "        monitor=  param_fit['monitor'],\n",
    "        mode = param_fit['mode'],\n",
    "        save_best_only= param_fit['save_best_only'],\n",
    "        verbose= param_fit['verbose']\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Modell fitten\n",
    "steps_per_epoch = int(np.floor((len(X_train_vec) / param_fit['batch_size'])))\n",
    "print(f\"Model Params.\\nbatch_size: {param_fit['batch_size']}\\nEpochs: {param_fit['epochs']}\\n\"\n",
    "    f\"Step p. Epoch: {steps_per_epoch}\\n\"\n",
    ")\n",
    "\n",
    "story = rnn_model.fit(\n",
    "    X_train_vec,\n",
    "    y_train,\n",
    "    batch_size = param_fit['batch_size'],\n",
    "    epochs= param_fit['epochs'],\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=(X_test_vec, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Das Mosell mit den besten Gewichte aktualisieren\n",
    "rnn_model.load_weights('Email_Classification/Models/Sequential Models\\\n",
    "/rnn/lstm/Checkpoint/2020-12-20_1926/weights.best.hdf5')\n",
    "score = rnn_model.evaluate(X_test_vec, \n",
    "                      y_test, \n",
    "                      verbose=1)\n",
    "print('Test loss:    ', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#Embedding-Schicht mittrainieren\n",
    "rnn_model.layers[1].trainable = True\n",
    "rnn_model.compile(loss= 'categorical_crossentropy',\n",
    "              optimizer= adam,\n",
    "              metrics=['accuracy'])\n",
    "steps_per_epoch = int(np.floor((len(X_train_vec) / param_fit['batch_size'])))\n",
    "print(f\"Model Params.\\nbatch_size: {param_fit['batch_size']}\\nEpochs: {param_fit['epochs']}\\n\"\n",
    "    f\"Step p. Epoch: {steps_per_epoch}\\n\")\n",
    "      \n",
    "story = rnn_model.fit(\n",
    "    X_train_vec,\n",
    "    y_train,\n",
    "    batch_size = param_fit['batch_size'],\n",
    "    epochs = 15,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    callbacks = callbacks,\n",
    "    validation_data=(X_test_vec, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modell mit der besten Gewichte speichern\n",
    "rnn_model.load_weights('Email_Classification/Models/Sequential Models\\\n",
    "/rnn/lstm/Checkpoint/2020-12-20_1926/weights.best.hdf5')\n",
    "path = 'Email_Classification/Models/Sequential Models/rnn/lstm/Checkpoint/2020-12-20_1926'\n",
    "rnn_model.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trainings- und Testmenge und Hyperparameterwerte speichern\n",
    "with open('Email_Classification/Models/Sequential Models/rnn/lstm/Checkpoint/\\\n",
    "2020-12-20_1926/feature/X_train_vec.npy', 'wb') as f:\n",
    "    np.save(f, X_train_vec)\n",
    "with open('Email_Classification/Models/Sequential Models/rnn/lstm/Checkpoint/\\\n",
    "2020-12-20_1926/feature/X_test_vec.npy', 'wb') as f:\n",
    "    np.save(f, X_test_vec)\n",
    "with open('Email_Classification/Models/Sequential Models/rnn/lstm/Checkpoint/\\\n",
    "2020-12-20_1926/feature/y_train.npy', 'wb') as f:\n",
    "    np.save(f, y_train)\n",
    "with open('Email_Classification/Models/Sequential Models/rnn/lstm/Checkpoint/\\\n",
    "2020-12-20_1926/feature/y_test.npy', 'wb') as f:\n",
    "    np.save(f, y_test)\n",
    "with open('Email_Classification/Models/Sequential Models/rnn/lstm/Checkpoint/\\\n",
    "2020-12-20_1926/params.pkl', 'wb') as f:\n",
    "    pickle.dump(f, params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
