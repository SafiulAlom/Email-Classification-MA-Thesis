{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Skripte laden\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "os.chdir('/home/safiul/email-classification')\n",
    "import data\n",
    "from Email_Classification.Functions.packages import *\n",
    "import Email_Classification.Functions.Functions as fn\n",
    "import Email_Classification.Functions.Helper as hp\n",
    "import Email_Classification.Functions.parameters as par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_process = par.params['param_process']\n",
    "param_nlp = par.params['param_nlp']\n",
    "param_lgb = par.params['param_lgb']\n",
    "param_rf = par.params['param_rf']\n",
    "param_nb = par.params['param_nb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pfade zur Speicherung der ML-Modelle festlegen\n",
    "path_nb = \"Email_Classification/Models/Nonsequential Models/Naive Bayes/tfidf\"\n",
    "path_lgb = 'Email_Classification/Models/Nonsequential Models/Light Gradient Boosting/tfidf'\n",
    "path_lr = \"Email_Classification/Models/Nonsequential Models/Logistic Regression/tfidf\"\n",
    "path_rf = \"Email_Classification/Models/Nonsequential Models/Random Forest/tfidf/zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 14s, sys: 14.6 s, total: 1min 29s\n",
      "Wall time: 1min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Dateien laden\n",
    "headers = pd.read_parquet(data.HEADERS_FILE)\n",
    "bodies = pd.read_parquet(data.BODIES_FILE)\n",
    "targets = features.zedsets.prepare_target_most_common(\n",
    "    pd.read_parquet(data.TARGETS_FILE),\n",
    "    target_column='target_category',\n",
    "    num_most_common_class=100\n",
    ")\n",
    "\n",
    "#Der E-Mail-Datensatz mit den notwendigen Spalten erstellen\n",
    "emails = fn.createDataFrameEmail(headers = headers, \n",
    "                                 bodies = bodies, \n",
    "                                 targets = targets, \n",
    "                                 sample_size = param_process['sample_size'], \n",
    "                                 seed = 125)\n",
    "del headers, bodies, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Der Datensatz auf Test- und Trainingsmenge aufteilen\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "model_selection.train_test_split(emails.emails, \n",
    "emails.target_category, test_size =  param_process['test_size']\n",
    "                                 , random_state = 123)\n",
    "#Konvertieren von kategorialen Labels in Zahlen\n",
    "LE = preprocessing.LabelEncoder()\n",
    "LE.fit(emails.target_category)\n",
    "y_full = LE.transform(emails.target_category)\n",
    "y_train = LE.transform(y_train)\n",
    "y_test = LE.transform(y_test)\n",
    "del emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18 s, sys: 25.3 s, total: 43.3 s\n",
      "Wall time: 5min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Datenvorverarbeiten\n",
    "TP = fn.Text_process(nchar = param_process['nchar'], \n",
    "                     rmDigits = param_process['rmDigits'], \n",
    "                     trans_lower= param_process['trans_lower'])\n",
    "TP.fit(X_train)\n",
    "X_train_TP = fn.multiprocess_array(TP, X_train)\n",
    "X_test_TP = fn.multiprocess_array(TP, X_test)\n",
    "X_train_TP = pd.concat(X_train_TP)\n",
    "X_test_TP = pd.concat(X_test_TP)\n",
    "del X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29.7 s, sys: 17.8 s, total: 47.5 s\n",
      "Wall time: 22min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Stemming\n",
    "CSL = fn.Text_normalizer(stem_lemma = param_process['stem_lemma'])\n",
    "CSL.fit(X_train_TP)\n",
    "X_train_TN = fn.multiprocess_array(CSL, X_train_TP)\n",
    "X_test_TN = fn.multiprocess_array(CSL, X_test_TP)\n",
    "X_train_TN = pd.concat(X_train_TN)\n",
    "X_test_TN = pd.concat(X_test_TN)\n",
    "X_train_TN_ = X_train_TN[X_train_TN.apply(lambda x: len(x.split())) != 0]\n",
    "X_test_TN_ = X_test_TN[X_test_TN.apply(lambda x: len(x.split())) != 0]\n",
    "y_train = y_train[X_train_TN.apply(lambda x: len(x.split())) != 0]\n",
    "y_test = y_test[X_test_TN.apply(lambda x: len(x.split())) != 0]\n",
    "del X_train_TP, X_test_TP, X_train_TN, X_test_TN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 22s, sys: 29.2 s, total: 2min 51s\n",
      "Wall time: 3min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Feature-Repr√§sentation und Feature-Selektion\n",
    "TF_tfidf = TfidfVectorizer(ngram_range = param_nlp['ngram_range'], \n",
    "                           max_features= 1000)\n",
    "TF_tfidf.fit(X_train_TN_)\n",
    "X_train_tfidf = fn.multiprocess_array(TF_tfidf, X_train_TN_)\n",
    "X_test_tfidf = fn.multiprocess_array(TF_tfidf, X_test_TN_)\n",
    "X_train_tfidf = sp.vstack(X_train_tfidf).toarray()\n",
    "X_test_tfidf = sp.vstack(X_test_tfidf).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.5 s, sys: 1.13 s, total: 12.6 s\n",
      "Wall time: 12.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.01)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#Training und Speicherung von Multinomial-Naive-Bayes-Modell\n",
    "NB = MultinomialNB(alpha= param_nb['alpha'], \n",
    "                   fit_prior=param_nb['fit_prior'])\n",
    "NB.fit(X_train_tfidf, \n",
    "       y_train)\n",
    "fn.writemodel(path_nb, \"NB_100000\", NB, makeZip= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#Training und Speicherung des Modells der logistischen Regression \n",
    "lr = LogisticRegression(penalty = 'l2',\n",
    "                         max_iter= 1000,\n",
    "                         C = 1.0,\n",
    "                         fit_intercept = True,\n",
    "                         tol = 1e-4,\n",
    "                         solver = 'sag',\n",
    "                         multi_class='multinomial',\n",
    "                         n_jobs = -1,\n",
    "                         verbose = 1,\n",
    "                         random_state = 125)\n",
    "lr.fit(X_train_tfidf, y_train)\n",
    "fn.writemodel(path_lr, \"lr_10000\", \n",
    "              rf, makeZip= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#Training und Speicherung des Modells der Random-Forest\n",
    "rf = RandomForestClassifier(random_state= param_rf['random_state'],\n",
    "                            criterion=param_rf['criterion'],\n",
    "                            max_features=param_rf['max_features'],\n",
    "                            n_estimators = param_rf['n_estimators'],\n",
    "                            min_samples_split = param_rf['min_samples_split'],\n",
    "                            max_samples = param_rf['max_samples'],\n",
    "                            min_impurity_decrease = param_rf['min_impurity_decrease'],\n",
    "                            max_depth = param_rf['max_depth'],\n",
    "                            n_jobs = param_rf['n_jobs'],\n",
    "                            verbose= param_rf['verbose']\n",
    "                           )                                         \n",
    "rf.fit(X_train_tfidf, y_train)\n",
    "fn.writemodel(path_rf, \"RF_2000\", rf, makeZip= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#Training und Speicherung des Modells der multinomialen Light-Gradient-Boosting \n",
    "param_lgb = par.params['param_lgb']\n",
    "train_data = lightgbm.Dataset(X_train_tfidf, label=y_train)\n",
    "test_data = lightgbm.Dataset(X_test_tfidf, label=y_test)\n",
    "LGB = lightgbm.train(param_lgb['parameters'],\n",
    "                       train_data,\n",
    "                       valid_sets=test_data,\n",
    "                       num_boost_round = param_lgb['num_boost_round'],\n",
    "                       early_stopping_rounds= param_lgb['early_stopping_rounds'],\n",
    "                      feval= param_lgb['feval']\n",
    "                      )\n",
    "fn.writemodel(path = path_lgb, filename = 'LGB_2000', \n",
    "              variable = LGB, makeZip= False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccc",
   "language": "python",
   "name": "ccc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
